{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"5G_and_cloud_conference","text":"工作是我们探索认识世界的的窗口，所以，热爱它。 — 一默 5G是什么? 移动通迅技术 能承载的应用场景(新增) 峰值速率 产业 1G 通话 2K bps 移动电话 2G 短信，文字邮件 10K bps 电话，BB机 3G 网络，音乐 3.8M bps 游戏，互联网 4G 1080影片 0.1-1G bps 电子支付，金融 5G 4K影片，VR直播，物理网 1-10G bps 传统行业,万物互联 5G主要特点： 高速度：承载更多的信息量，1G高清视频数据只需要几秒。 低延时：5G在接入网边缘部署计算，处理和存储功能的云计算设备，使核心网控制功能下沉，减少端到端的传输，减少延时。 大容量：手表等无这里指承载终端数量大，5G采用高频率，但高频率的信号波长短，需要使用更多的微基站，微基站能部署在城市的任何位置，反而能连接更多的设备终端，万物互联成为可能。4G 每平方公里只能支持10个设备，容纳设备有限。 缺点嘛，都源于：高频率波，穿透性差 邓小平说：“科技是第一生产力”。每一次技术革命都带了新了经济增长，5G技术会影响未来20年的经济。所以这是兵家必争之地。 视频会议软件5G的普及，疫情的影响，会对视频会议软件产生如何的影响？ 我已经在新闻里多次看到视频会议，教育，甚至视频手术的影子。大胆想象，万物相连，任何一个设备，有屏，就可以时实沟通，共享场景，解决“当下”紧急问题。如此看来，属于未来系列中的基础需求，很有价值。 阶段 技术标准 应用 主要功能 专用网数字电视会议 H.200系列 国际电视会议，需要通过卫星，光纤等专用网格，费用高 无 基于IP网络视频会议 H.264 WebEx,GIPS 电话会议，文档共享，即实聊天 云视频会议 WebRTC ？ 屏幕共享,录音，录制，全终端支持 什么是WebRTCWebRTC 全称 Web Real-Time Communication。，Google开源GIPS后，与其它机构制定了行业标准，组成了WebRTC。 它并不是单一的协议， 包含了音视频采集，编解码，加密、传输，音视频展示等在内的多个协议标准以及一套基于 JavaScript 的 API，开源，免专利费。通过简单易用的 JavaScript API ，在不安装任何插件的情况下，让浏览器拥有了 P2P音视频和数据分享的能力。 WebRTC 的核心组件 音视频引擎：OPUS、VP8 / VP9、H264 传输层协议：底层传输协议为 UDP, 也可TCP 媒体协议：SRTP / SRTCP 数据协议：DTLS / SCTP P2P 内网穿透：STUN / TURN / ICE / Trickle ICE 信令与 SDP 协商：HTTP / WebSocket / SIP、 Offer Answer 模型 总结作为新人，想要了解云视频开发，从WebRTC入手是必经之路。 附思 即然有屏都可共享“当下”，那么有屏且有网的的地方就能由超级管理员实时监控啊。","link":"/2021/10/29/5G-and-cloud-conference/"},{"title":"第一篇：接受当下","text":"2021-10-18 个人快照迟迟不知如何开始写第一篇博文，但在“追求完美就是最大的障碍”的暗示下，写下本篇， 这是一个总结。 朋友圈总是看到很多人幸福的瞬间，对比当下我的状态，很是糟糕，所有我屏蔽了朋友圈。周四，周五濒临失控，打开联系人却不知道找谁，最终找到了常常去寺里做佛事的朋友。我将烦恼通通诉说给了他。他向我推荐了一个up主,安大熊。于是我的书单里多了两项紧急阅读书《重新认识你自己》，《自卑与超越》。我失控了，我的状态生病了，先爱惜自己，放下欲望，我需要慢下来，好好休息，好好运动。先把身体维持在一个较好的水平。 工作最近工作很无心，戒断公司咖啡导致的偏头疼。工作内容不饱和，需要自己安排工作内容。目前晋升无望。目前的下一个计划是打算将并发并行好好梳理并分享。再下一个计算是梳理Cache并分享。 生活九月一本书没看，十月略看了两本书， 《游戏力养育》，《股市真规则》，然则，读书而不实践，等于白读。计划每月做一次资产负债表。 情绪《为何家会伤人》，家最会伤人。我爱我母亲同时也恨她，无时无刻她都在念叨着家人的不好，指责这里做不好，哪里做不好，明明每个人都有自己的分工，都在做份内之事， 如果她不愿意做,我提议可以分给别人出来，可她不，她会说别人做得不好，横加指责，然后接着自己继续做。搞得我很不喜欢这样的“家”。对家人发火，对外人格外亲切。慢慢的我是不是也习得了这样的不良行为。我害怕。","link":"/2021/10/18/accept-yourself/"},{"title":"深入Cache(3) --- JAVA本地缓存，占用应用存储","text":"Backend在单体服务时，也有缓存需求时，缓存的数据是服务本地申请的内存里的，这时就提供了类似Ehcache, Guava Cache等lib。 这样的cache只对单个service node有效，当然我们也可以直接用ConcurrentHashMap来缓存我们的数据，但是要想做到cache一般支持的容量大小，过期策略等还需要做大量开发工作。 注意：java sun.misc.Cache 是个很简单的cache, 并不强大，在JDK11中已经被移除掉了,本文不做研究。 EhcacheEhcache 广泛用于JAVA的Spring框架，可以和Hibernate, mybatis, shiro等结合使用。（默认hibernate，mybatis只有一级缓存，二级缓存关闭的，见附录1）。 特点： 它提供了cache一般的需要的缓存失效策略，如LRU,LFU,FIFO等。也支持基于cache和基于element的过期策略。每个cache的存活时间可控。 分两级缓存，内存和碰盘，可以使用JVM的堆外内存。因此无须担心容量的问题。 可持久化，cache data会在虚拟机重启过程中flush到磁盘。 可通过RMI, 可插入API等方式进行分布式缓存。 提供cache管理器的侦听接口。 应用开发需要关注核心 CacheManager: 一个app可以有多个CacheManager, 它是使用Ehcache的入口。 Cache:一个CacheManager 可以管理多个Cache, 每个Cache用hash方式管理多个element. Element：key-value 存储的实际数据。 SOR(System of record): 可以取得数据的的真实数据源，可以是redis等下级缓存，也可以直接是database. 使用Ehcache的场景： update SOR 较少， 即读多写少。 对并发要求不严格，对一致性要求不高。 如果是多台服务的的情况下，可能出现某一台本地缓存变成脏数据， 同台同步是个问题(术语：缓存漂移)。 也有一定的解决方案： 每台服务器定时轮询，刷新最新的数据。 主动通知，接入zooKeeper，侦听MQ消息。 Example Of Ehcache 代码示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class EhcacheExample { private static CacheManager cacheManager = CacheManagerConfig .createCacheManager(&quot;cache-1&quot;, String.class, String.class); public static void main(String[] args) { /** * off-heap 堆外内存，因为需要序列化和反序列化，因为较on-heap更慢。但on-heap会占用heap，影响gc. * disk 除了要序列化和反序列化，还需要磁盘I/O,因此最慢 */ Cache&lt;Long, String&gt; myCache = cacheManager.createCache(&quot;cache-2&quot;, CacheConfigurationBuilder .newCacheConfigurationBuilder(Long.class, String.class, ResourcePoolsBuilder.newResourcePoolsBuilder() .heap(2, EntryUnit.ENTRIES) .offheap(1, MemoryUnit.MB) .disk(2, MemoryUnit.MB, true)) .withExpiry(ExpiryPolicyBuilder.timeToLiveExpiration(Duration.ofDays(1))) //过期配置 .withEvictionAdvisor(new OddKeysEvictionAdvisor&lt;&gt;()) //缓存淘汰策略,默认是LRU,这里提供自定义 .withLoaderWriter(new SampleLoaderWriter&lt;&gt;()) // 参考：Cache-as-SoR .build()); ListenerObject listener = new ListenerObject(); myCache.getRuntimeConfiguration().registerCacheEventListener(listener, EventOrdering.ORDERED, EventFiring.ASYNCHRONOUS, EnumSet.of(EventType.UPDATED, EventType.CREATED, EventType.REMOVED, EventType.EVICTED, EventType.EXPIRED)); if (!write2MyCache(myCache, 1L, &quot;ssss&quot;)) concurrentGet(myCache, 1L); }}public class CacheManagerConfig { public static &lt;K, V&gt; CacheManager createCacheManager(String cacheName, Class&lt;K&gt; keyType, Class&lt;V&gt; valueType) { return CacheManagerBuilder.newCacheManagerBuilder() .with(CacheManagerBuilder.persistence(getPath() + File.separator + &quot;Cache&quot;)) .withCache(cacheName, CacheConfigurationBuilder.newCacheConfigurationBuilder( keyType, valueType, ResourcePoolsBuilder.heap(10))) .build(true); } private static String getPath() { String path = CacheManagerConfig.class.getResource(&quot;/&quot;).getPath(); System.out.println(&quot;CacheManagerConfig ClassLoader path:&quot; + path); return path; }} Guava Cache 简言而之：它是一个支持LRU的ConcurrentHashMap, 只提供了CURD， 过期时间 等简单功能。不多展开主要实现的缓存功能有： 自动将entry节点加载进缓存结构中； 当缓存的数据超过设置的最大值时，使用LRU算法移除； 具备根据entry节点上次被访问或者写入时间计算它的过期机制； 缓存的key被封装在WeakReference引用内； 缓存的Value被封装在WeakReference或SoftReference引用内； 统计缓存使用过程中命中率、异常率、未命中率等统计数据。 对比Ehcache，不同点 Guava Cache不能持久化到磁盘 Ehcache有集群方案（较少使用，一般都redis了），Guava没有 Guava仅支持Cache-aside使用方式和实现read-through。ehcache更强大一些。 使用Guava Cache的场景（略，同ehcache一样）： 和Ehcache一样，都是本地存储，多服务器时都会存在一致性问题。 CaffeineCaffeine是基于Java8，对Guava缓存的重写版本，在Spring Boot 2.0中将取代Guava，基于LRU算法实现，支持多种缓存过期策略。 附录 ORM的一级缓存和二级缓存是什么？ 一级缓存：在一个sqlsession的作用域（简单理解为一次事务中）中共享的缓存对象，update操作， session flush, session close 会让一级缓存失效。 二级缓存：默认关闭，也称查询缓存，在多个sqlsession之间共享缓存对象。在进入一级缓存查询之前，会先查二级缓存。 — 静态配置适合二级缓存。 Spring Cache是由 Spring Framework 提供的一个缓存抽象层，接入各种缓存解决方案来进行使用，通过 Spring Cache 的集成，我们只需要通过一组注解来操作缓存就可以了。目前支持的有EhCache、Redis、Caffeine、guava cache.等主流的本地缓存方案。其主要的原理就是向 Spring Context 中注入 Cache 和 CacheManager 这两个 bean，再通过 Spring Boot 的自动装配技术，会根据项目中的配置文件自动注入合适的 Cache 和 CacheManager 实现。Spring不进行Cache的缓存策略的维护，这些都是由底层Cache自己实现，Spring只是提供了一个Wrapper，提供一套对外一致的API。 如果没有提供，默认使用ConcurrentHashMap。","link":"/2021/12/01/cache-local-cache/"},{"title":"深入Cache(1) --- CPU和主存之间","text":"本次知识梳理，用3W法。 what, why, how? what：界定问题，搞清楚问题到底是什么； why：分析问题，结构化分析问题的本质原因是什么； how：解决问题，应用目标导向思维解决问题； What：问题是什么？访问太慢！举例：页面次次加载静态资源，慢; 后端服务器直接从数据库获取数据，慢; CPU直接从主存取数据，慢。 Why: 为什么要使用缓存？技术人员为了提高系统的性能，包括响应时间，延迟时间，吞吐量，并发用户数和资源利用率等，用这些指标提高用户体验且节省成本。所以需要把已经取得过的数据，存储在较近较快的地方，便于访问。所以在计算机中缓存随处可见，页面缓存，浏览器缓存，数据库缓存，CPU里的L1,L2,L3级缓存。 How: cache如何解决这个问题？ 以CPU缓存展开详说。局域性原理一个重要的基本事实：程序常常重复使用它们最近用过的数据和指令。 一个程序90%的执行时间花费在仅10%的代码中。 时间局域性是指最近访问过的内容很可能会短期内被再次访问。 空间局域性是指地址相互临近的项目很可能会在短时间内都被用到。 CPU和主存间的速度问题 程序员想拥有足够大的“快速”存储，快速存储非常昂贵，根据局域性原理：大多数程序都不会均衡的访问所有的代码和数据。由此，“在给定的实现技术和功率预算下，硬件越小，速度越快”，就产生了存储的层次结构。这些层次由不同速度，不同大小的存储器组成。 L1缓分成两种，一种是指令缓存，一种是数据缓存。L2缓存和L3缓存不分指令和数据。 L1和L2缓存在每一个CPU核中，L3则是所有CPU核心共享的内存。L1、L2、L3的越离CPU近就越小，速度也越快，越离CPU远，速度也越慢。 CPU高速缓存的结构 一个缓存划分为S个组，一个组有E个缓存行（cache line）,一行只有一个B字节的缓存块block。 每个cache一个有效位(valid bit)指明该cache line是否包含有意义的信息。 高速缓存的大小C= B * E * S CPU &lt;—&gt; Cache: 是以word(字,大小随CPU架构) 传输的，速度fast. Cache &lt;–&gt; 主存: 是以块传输的(cache block)，一块大小为B=2^b。 检索数据，Read操作 —- 缓存命中的过程 CPU读取字的过程分为：组选择-&gt;行匹配-&gt;字抽取。 组选择， 地址中的S标记，定位到组 行匹配， 地址中的tag标记与组的所有行匹配行t标记位，如果有匹配的行，就命中，否则不命中。 字抽取， 若读命中，再由地址中的b位计算出在块中的偏移位置，从而找到字。 若读未命中，从下级存储读出来写入缓存（会产生问题：缓存满了怎么办？），然后再写到被读入的字单元。 问题一：向缓存写数据，缓存满了怎么办？引入缓存失效方案 Least-Recently-Used(LRU) : 替换掉最近被请求最少的对象。在CPU缓存淘汰和虚拟内存系统中效果很好。浏览器一般使用了LRU作为缓存算法。新的对象会被放在缓存的顶部，当缓存达到容量的极限时，底部对象被去除，方法就是把最新被访问的缓存对象放到缓存池的顶部。 Least-Frequently-Used(LFU)：替换掉访问次数最少的缓存，保留最常用的数据。缺点是早期被使用多次的记录之后再不会用到，在该策略下，也很难被删掉，造成”缓存污染“。 Two Queues(2Q)：把被访问的数据放到LRU的缓存中，如果这个对象再一次被访问，就转移到第二个更大的LRU缓存，即使用多级缓存的方式。两个队列都是LRU算法：容量满，底部对象被删掉。 First In First Out(FIFO)：通过一个先进先出队列跟踪缓存对象，最近访问的放到最后，更早的放在前面，当缓存容量满时，del最前面的缓存对象. 问题二：写入缓存操作，缓存与下级缓存，缓存与同级缓存，数据一致性如何保证？（复杂） 要保持数据更新，需要在合适的时候把写数据，传播下去。 一般有两种回写策略：回写（Write back）和直写（Write through）。 write through（直写）：直写是简单的方式，数据更新当前cache, 并直接写入下级存储中，对其更新。 缺点：每次写都会引起总线流量。 write back（回写）：仅更新当前cache，推迟更新下一级存储的更新，在当前数据所在的块（block）要被替换算法替换时，再将它flush回下级回存储器。新的问题产生了，此时Cache中的数据与Memory中的数据不一致，Cache中的数据就变成了脏数据(dirty)。如果其他部件（DMA， 另一个核）访问这段数据的时候，就需要通过 Cache一致性协议(Cache coherency protocol) 保证取到的是最新的数据。 参考：Cache一致性协议 问题：如何处理写未命中（write-misses）? 我们要知道，当前 cpu 向最近的存储发起一个 write request的请求，是没有response data返回给CPU的， 所以需要决定可能发生write-misses如何处理—这又有两种策略： write-allocate: 写分配，即，从低一层的cache中加载相应的 block 到 current cache, 然后再write更新这个 block. not-write-allocate: 避开 current cache, 直接把这个字写到低一层的cache中。 write through通常配合的是not-write-allocate。 write back 通常搭配 write-allocate。 细节随系统不同而不同，通常私有，无文档记录。 编写高速缓存友好的代码 好的程序员总是应该尝试着去编写高速缓存友好的代码。 1. 让最常见的情况运行的更快。 : 需要把注意力集中在核心函数的循环上。2. 对局部变量的反复引用是好的–时间局部性。 :3. 步长为1的引用模式是好的–空间局部性。 : ExampleBad: 12345678int sumarrycols(int a[M][N]){ int i, j, sum=0; for(j=0; j&lt;N; j++) for(i=0; i&lt;M; i++) sum += a[i][j]; //每次步长为 M return sum;} Good: 12345678int sumarrycols(int a[M][N]){ int i, j, sum=0; for(i=0; i&lt;M; i++) for(j=0; j&lt;N; j++) sum += a[i][j]; //每次步长为 1 return sum;} 思考：局部性原理和2/8定理很相似，聪明的人能把原理扩展应用到生活工作设计中，愚钝如我，面对这些原理，只知道：“对啊，很简单”。 然后就没有下文了。为什么？","link":"/2021/11/23/cache-tech/"},{"title":"深入Cache(2) --- 缓存的使用模式","text":"问：我们如何使用缓存？一个普遍的情况，缓存仅仅是缓存，我们read-miss时，去load数据源，update时，先update 数据源，再update cache. 这只是其中一种使用模式，称为Cache-Aside。那么还有哪些模式呢？ 可不可缓存就当做数据源？我们在CPU缓存那里，遇到了write-back, write-through，在应用层是否可以借鉴其思想？ 模式一： Cache-asideRead 场景(伪代码) 12345v = cache.get(k)if (v == null) { v = sor.get(k) cache.put(k, v)} Write 场景(伪代码) 123v = newVsor.put(k, v)cache.put(k, v) Cache-aside 优势和劣势 需要解决缓存穿透问题：同一个key,Cache,SoR都是NULL,每次给的都是空。 需要解决缓存击穿问题：同一个key,Cache没有，SoR有，热点key在失效情况下，被大量get同时访问到SoR。 需要解决缓存雪崩问题: 大量key到期，请求全到SoR，可能引起SoR down机。 模式二： Cache-as-SoR （system-of-record） 把缓存当做最终数据源，读，写处理都交给了cache, 应用层代码完全免责。这种情况cache本身应当支持哪些行为或者配置呢？ 读方案：Read-through（直读）Read 场景(伪代码) 1234567891011//cacheLoader 配置CacheBuilder.newBuilder() .softValues() .maximumSize(5000).expireAfterWrite(2, TimeUnit.MINUTES) .build(new CacheLoader&lt;Integer,Result&lt;Category&gt;&gt;() { // 缓存没有值时，会委托给CacheLoader, 从SoR里读取,写入缓存，返回value @Override public Result&lt;Category&gt; load(final Integer sortId) throwsException { return categoryService.get(sortId); } }); 12345//业务代码v = cache.get(k)if (v == null) { v = sor.get(k)} 写方案一：Write-through（直写）更新SoR优先。 通过一个writer component，like ehcache.CacheWriter，需要业务代码配置如何写入SoR.写SoR就委拖给了Cache。数据一致性得到保证。过程：cache.put(key) -&gt; CacheLoaderWriter写SoR -&gt; SoR成功后，再写入Cache. 写方案二：write-behind（直写）更新缓存优先，cache内部使用线程池异步写，延迟写SoR，业务线程可以先返回。缺点在于，如果缓存失效，数据可能永久丢失。 Cache-as-SoR 优势和劣势Advantages 集中的代码配置read-write的方式 可以方便解决缓存穿透等等问题，因为在CacheLoader里集中load时，可以写同步代码限制一个请求去拿。 每个cache可独立选择write的方式 Disadvantage 怎么使用cache在逻辑里不直观 问：如何选择何种模式？根据使用场景，提问思考再选择： 系统是写多读少的吗？(例如基于时间的日志) 数据是否是只写入一次并被读取多次?(例如用户配置文件) 返回的数据总是惟一的吗?(例如搜索查询) 使用缓存后，命中率如何？ 参考： https://www.ehcache.org/documentation/3.9/caching-patterns.html","link":"/2021/11/30/cache-usage-patterns/"},{"title":"深入Cache(4) --- 分布式缓存","text":"不同于本地缓存，分布式缓存将cache和服务独立开，可个服务之间可以共享。","link":"/2021/11/29/catch-redis/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/10/27/hello-world/"}],"tags":[{"name":"科技","slug":"科技","link":"/tags/%E7%A7%91%E6%8A%80/"},{"name":"总结","slug":"总结","link":"/tags/%E6%80%BB%E7%BB%93/"},{"name":"cache， Ehcache","slug":"cache，-Ehcache","link":"/tags/cache%EF%BC%8C-Ehcache/"},{"name":"Guava","slug":"Guava","link":"/tags/Guava/"},{"name":"计算机原理","slug":"计算机原理","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"},{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"cache， redis","slug":"cache，-redis","link":"/tags/cache%EF%BC%8C-redis/"}],"categories":[{"name":"编程","slug":"programming","link":"/categories/programming/"},{"name":"其它","slug":"其它","link":"/categories/%E5%85%B6%E5%AE%83/"}]}