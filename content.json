{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"5G_and_cloud_conference","text":"工作是我们探索认识世界的的窗口，所以，热爱它。 — 一默 5G是什么? 移动通迅技术 能承载的应用场景(新增) 峰值速率 产业 1G 通话 2K bps 移动电话 2G 短信，文字邮件 10K bps 电话，BB机 3G 网络，音乐 3.8M bps 游戏，互联网 4G 1080影片 0.1-1G bps 电子支付，金融 5G 4K影片，VR直播，物理网 1-10G bps 传统行业,万物互联 5G主要特点： 高速度：承载更多的信息量，1G高清视频数据只需要几秒。 低延时：5G在接入网边缘部署计算，处理和存储功能的云计算设备，使核心网控制功能下沉，减少端到端的传输，减少延时。 大容量：手表等无这里指承载终端数量大，5G采用高频率，但高频率的信号波长短，需要使用更多的微基站，微基站能部署在城市的任何位置，反而能连接更多的设备终端，万物互联成为可能。4G 每平方公里只能支持10个设备，容纳设备有限。 缺点嘛，都源于：高频率波，穿透性差 邓小平说：“科技是第一生产力”。每一次技术革命都带了新了经济增长，5G技术会影响未来20年的经济。所以这是兵家必争之地。 视频会议软件5G的普及，疫情的影响，会对视频会议软件产生如何的影响？ 我已经在新闻里多次看到视频会议，教育，甚至视频手术的影子。大胆想象，万物相连，任何一个设备，有屏，就可以时实沟通，共享场景，解决“当下”紧急问题。如此看来，属于未来系列中的基础需求，很有价值。 阶段 技术标准 应用 主要功能 专用网数字电视会议 H.200系列 国际电视会议，需要通过卫星，光纤等专用网格，费用高 无 基于IP网络视频会议 H.264 WebEx,GIPS 电话会议，文档共享，即实聊天 云视频会议 WebRTC ？ 屏幕共享,录音，录制，全终端支持 什么是WebRTCWebRTC 全称 Web Real-Time Communication。，Google开源GIPS后，与其它机构制定了行业标准，组成了WebRTC。 它并不是单一的协议， 包含了音视频采集，编解码，加密、传输，音视频展示等在内的多个协议标准以及一套基于 JavaScript 的 API，开源，免专利费。通过简单易用的 JavaScript API ，在不安装任何插件的情况下，让浏览器拥有了 P2P音视频和数据分享的能力。 WebRTC 的核心组件 音视频引擎：OPUS、VP8 / VP9、H264 传输层协议：底层传输协议为 UDP, 也可TCP 媒体协议：SRTP / SRTCP 数据协议：DTLS / SCTP P2P 内网穿透：STUN / TURN / ICE / Trickle ICE 信令与 SDP 协商：HTTP / WebSocket / SIP、 Offer Answer 模型 总结作为新人，想要了解云视频开发，从WebRTC入手是必经之路。 附思 即然有屏都可共享“当下”，那么有屏且有网的的地方就能由超级管理员实时监控啊。","link":"/2021/10/29/5G-and-cloud-conference/"},{"title":"第一篇：接受当下","text":"2021-10-18 个人快照迟迟不知如何开始写第一篇博文，但在“追求完美就是最大的障碍”的暗示下，写下本篇， 这是一个总结。 朋友圈总是看到很多人幸福的瞬间，对比当下我的状态，很是糟糕，所有我屏蔽了朋友圈。周四，周五濒临失控，打开联系人却不知道找谁，最终找到了常常去寺里做佛事的朋友。我将烦恼通通诉说给了他。他向我推荐了一个up主,安大熊。于是我的书单里多了两项紧急阅读书《重新认识你自己》，《自卑与超越》。我失控了，我的状态生病了，先爱惜自己，放下欲望，我需要慢下来，好好休息，好好运动。先把身体维持在一个较好的水平。 工作最近工作很无心，戒断公司咖啡导致的偏头疼。工作内容不饱和，需要自己安排工作内容。目前晋升无望。目前的下一个计划是打算将并发并行好好梳理并分享。再下一个计算是梳理Cache并分享。 生活九月一本书没看，十月略看了两本书， 《游戏力养育》，《股市真规则》，然则，读书而不实践，等于白读。计划每月做一次资产负债表。 情绪《为何家会伤人》，家最会伤人。我爱我母亲同时也恨她，无时无刻她都在念叨着家人的不好，指责这里做不好，哪里做不好，明明每个人都有自己的分工，都在做份内之事， 如果她不愿意做,我提议可以分给别人出来，可她不，她会说别人做得不好，横加指责，然后接着自己继续做。搞得我很不喜欢这样的“家”。对家人发火，对外人格外亲切。慢慢的我是不是也习得了这样的不良行为。我害怕。","link":"/2021/10/18/accept-yourself/"},{"title":"深入Cache(3) --- JAVA本地缓存，占用应用存储","text":"Backend在单体服务时，也有缓存需求时，缓存的数据是服务本地申请的内存里的，这时就提供了类似Ehcache, Guava Cache等工具。 这样的cache只对单个service node有效，当然我们也可以直接用ConcurrentHashMap来缓存我们的数据，但是要想做到cache一般支持的容量大小，过期策略等还需要做大量开发工作。 注意：java sun.misc.Cache 是个很简单的cache, 并不强大，在JDK11中已经被移除掉了,本文不做研究。 下面我们先介绍ehcache，它功能更全面，更强大，了解了ehcache， guava, Caffeinet可以一笔代过。 EhcacheEhcache 广泛用于JAVA的Spring框架，可以和Hibernate, mybatis, shiro等结合使用。（默认hibernate，mybatis只有一级缓存，二级缓存关闭的，见附录1）。 特点： 它提供了cache一般的需要的缓存失效策略，如LRU,LFU,FIFO等。也支持基于cache和基于element的过期策略。每个cache的存活时间可控。 分两级缓存，内存和碰盘，可以使用JVM的堆外内存。因此无须担心容量的问题。 可持久化，cache data会在虚拟机重启过程中flush到磁盘。 可通过RMI, 可插入API等方式进行分布式缓存。 提供cache管理器的侦听接口。 应用开发需要关注核心 CacheManager: 一个app可以有多个CacheManager, 它是使用Ehcache的入口。 Cache:一个CacheManager 可以管理多个Cache, 每个Cache用hash方式管理多个element. Element：key-value 存储的实际数据。 SOR(System of record): 可以取得数据的的真实数据源，可以是redis等下级缓存，也可以直接是database. Example Of Ehcache 代码示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class EhcacheExample { private static CacheManager cacheManager = CacheManagerConfig .createCacheManager(&quot;cache-1&quot;, String.class, String.class); public static void main(String[] args) { /** * off-heap 堆外内存，因为需要序列化和反序列化，因为较on-heap更慢。但on-heap会占用heap，影响gc. * disk 除了要序列化和反序列化，还需要磁盘I/O,因此最慢 */ Cache&lt;Long, String&gt; myCache = cacheManager.createCache(&quot;cache-2&quot;, CacheConfigurationBuilder .newCacheConfigurationBuilder(Long.class, String.class, ResourcePoolsBuilder.newResourcePoolsBuilder() .heap(2, EntryUnit.ENTRIES) .offheap(1, MemoryUnit.MB) .disk(2, MemoryUnit.MB, true)) .withExpiry(ExpiryPolicyBuilder.timeToLiveExpiration(Duration.ofDays(1))) //过期配置 .withEvictionAdvisor(new OddKeysEvictionAdvisor&lt;&gt;()) //缓存淘汰策略,默认是LRU,这里提供自定义 .withLoaderWriter(new SampleLoaderWriter&lt;&gt;()) // 参考：Cache-as-SoR .build()); ListenerObject listener = new ListenerObject(); myCache.getRuntimeConfiguration().registerCacheEventListener(listener, EventOrdering.ORDERED, EventFiring.ASYNCHRONOUS, EnumSet.of(EventType.UPDATED, EventType.CREATED, EventType.REMOVED, EventType.EVICTED, EventType.EXPIRED)); if (!write2MyCache(myCache, 1L, &quot;ssss&quot;)) concurrentGet(myCache, 1L); }}public class CacheManagerConfig { public static &lt;K, V&gt; CacheManager createCacheManager(String cacheName, Class&lt;K&gt; keyType, Class&lt;V&gt; valueType) { return CacheManagerBuilder.newCacheManagerBuilder() .with(CacheManagerBuilder.persistence(getPath() + File.separator + &quot;Cache&quot;)) .withCache(cacheName, CacheConfigurationBuilder.newCacheConfigurationBuilder( keyType, valueType, ResourcePoolsBuilder.heap(10))) .build(true); } private static String getPath() { String path = CacheManagerConfig.class.getResource(&quot;/&quot;).getPath(); System.out.println(&quot;CacheManagerConfig ClassLoader path:&quot; + path); return path; }} Guava Cache 简言而之：它是一个支持LRU的ConcurrentHashMap, 只提供了CURD， 过期时间 等简单功能。不多展开主要实现的缓存功能有： 自动将entry节点加载进缓存结构中； 当缓存的数据超过设置的最大值时，使用LRU算法移除； 具备根据entry节点上次被访问或者写入时间计算它的过期机制； 缓存的key被封装在WeakReference引用内； 缓存的Value被封装在WeakReference或SoftReference引用内； 统计缓存使用过程中命中率、异常率、未命中率等统计数据。 对比Ehcache，不同点 Guava Cache不能持久化到磁盘 Ehcache有集群方案（较少使用，一般都redis了），Guava没有 Guava仅支持Cache-aside使用方式和实现read-through。ehcache更强大一些。 CaffeineCaffeine是基于Java8，对Guava缓存的重写版本，在Spring Boot 2.0中将取代Guava，基于LRU算法实现，支持多种缓存过期策略。 使用本地缓存的场景： update SOR 较少， 即读多写少。 对并发要求不严格，对一致性要求不高。 如果是多台服务的的情况下，可能出现某一台本地缓存变成脏数据， 同台同步是个问题(术语：缓存漂移)。 也有一定的解决方案： 每台服务器定时轮询，刷新最新的数据。 主动通知，接入zooKeeper，侦听MQ消息。 附录 ORM的一级缓存和二级缓存是什么？ 一级缓存：在一个sqlsession的作用域（简单理解为一次事务中）中共享的缓存对象，update操作， session flush, session close 会让一级缓存失效。 二级缓存：默认关闭，也称查询缓存，在多个sqlsession之间共享缓存对象。在进入一级缓存查询之前，会先查二级缓存。 — 静态配置适合二级缓存。 Spring Cache是由 Spring Framework 提供的一个缓存抽象层，接入各种缓存解决方案来进行使用，通过 Spring Cache 的集成，我们只需要通过一组注解来操作缓存就可以了。目前支持的有EhCache、Redis、Caffeine、guava cache.等主流的本地缓存方案。其主要的原理就是向 Spring Context 中注入 Cache 和 CacheManager 这两个 bean，再通过 Spring Boot 的自动装配技术，会根据项目中的配置文件自动注入合适的 Cache 和 CacheManager 实现。Spring不进行Cache的缓存策略的维护，这些都是由底层Cache自己实现，Spring只是提供了一个Wrapper，提供一套对外一致的API。 如果没有提供，默认使用ConcurrentHashMap。","link":"/2021/12/01/cache-local-cache/"},{"title":"缓存总结","text":"什么时候使用缓存？ 缓存并不是一开始就考虑加入我们的系统的，当遇到性能瓶颈时，才可能需求引入缓存。如果业务面临的场景规模小，访问量小或是在初期阶段就加入缓存，反而会增加开发，运维的复杂性。记住一点：缓存是为了解决性能问题而生的！缓存适合“read more, write less”的业务场景。 如何使用缓存 参考cache第二篇。 如何监控缓存？通常需要监控的指标 监控项 说明 扩展 keys count 缓存对象的总数 - used memory 内存使用量 - free memory 可用内存 - cpu cpu 使用率 - hits/s 每秒命中数 redis info 查看 keyspace_hits,keyspace_misses miss/s 每秒未命中数 redis可以使用开源工具监控，如 redis-stat redis, memcached 存储的数据是字节类型，需要进行序列化转成字节进行set cache 和反序列化load到本地，在批量操作的情况下，该操作开销可能导致CPU使用率过高。参考：https://github.com/eishay/jvm-serializers/wiki 本地缓存额外监控项 数据位置 监控项 on-heap GC频率 on-heap heap使用量 影响命中率的因素 读写比例 缓存的数据粒度越小，命中率越高 缓存的容量 缓存节点是否故障 管理缓存可能遇到的场景 缓存穿透：可以考虑引入空值，cache直接返回空值。 缓存失效：缓存的过期时间不要一致，可以设定一些随机范围。 数据一致性：强一致性用户体验不好，我们绝大部份场景，追求最终一致性。在write缓存失败的情况下，可能通过补偿逻辑，达到最终一致性。 热点数据：虽然sharding己经将key分布到不同的机器上，但是同一个key的访问都是同一个缓存服务，如个这个key是个热点，就会出现性能瓶颈。一般解决方案：[数据预热-提前读入缓存]，[热点key数据复制：热点数据每台cache server都有，cache client路由选择一个cache server读取。更新时，删除所有的key_salt], [多级缓存（略）]","link":"/2021/12/06/cache-summary/"},{"title":"深入Cache(1) --- CPU和主存之间","text":"本次知识梳理，用3W法。 what, why, how? what：界定问题，搞清楚问题到底是什么； why：分析问题，结构化分析问题的本质原因是什么； how：解决问题，应用目标导向思维解决问题； What：问题是什么？访问太慢！举例：页面次次加载静态资源，慢; 后端服务器直接从数据库获取数据，慢; CPU直接从主存取数据，慢。 Why: 为什么要使用缓存？技术人员为了提高系统的性能，包括响应时间，延迟时间，吞吐量，并发用户数和资源利用率等，用这些指标提高用户体验且节省成本。所以需要把已经取得过的数据，存储在较近较快的地方，便于访问。所以在计算机中缓存随处可见，页面缓存，浏览器缓存，数据库缓存，CPU里的L1,L2,L3级缓存。 How: cache如何解决这个问题？ 以CPU缓存展开详说。局域性原理一个重要的基本事实：程序常常重复使用它们最近用过的数据和指令。 一个程序90%的执行时间花费在仅10%的代码中。 时间局域性是指最近访问过的内容很可能会短期内被再次访问。 空间局域性是指地址相互临近的项目很可能会在短时间内都被用到。 CPU和主存间的速度问题 程序员想拥有足够大的“快速”存储，快速存储非常昂贵，根据局域性原理：大多数程序都不会均衡的访问所有的代码和数据。由此，“在给定的实现技术和功率预算下，硬件越小，速度越快”，就产生了存储的层次结构。这些层次由不同速度，不同大小的存储器组成。 L1缓分成两种，一种是指令缓存，一种是数据缓存。L2缓存和L3缓存不分指令和数据。 L1和L2缓存在每一个CPU核中，L3则是所有CPU核心共享的内存。L1、L2、L3的越离CPU近就越小，速度也越快，越离CPU远，速度也越慢。 CPU高速缓存的结构 一个缓存划分为S个组，一个组有E个缓存行（cache line）,一行只有一个B字节的缓存块block。 每个cache一个有效位(valid bit)指明该cache line是否包含有意义的信息。 高速缓存的大小C= B * E * S CPU &lt;—&gt; Cache: 是以word(字,大小随CPU架构) 传输的，速度fast. Cache &lt;–&gt; 主存: 是以块传输的(cache block)，一块大小为B=2^b。 检索数据，Read操作 —- 缓存命中的过程 CPU读取字的过程分为：组选择-&gt;行匹配-&gt;字抽取。 组选择， 地址中的S标记，定位到组 行匹配， 地址中的tag标记与组的所有行匹配行t标记位，如果有匹配的行，就命中，否则不命中。 字抽取， 若读命中，再由地址中的b位计算出在块中的偏移位置，从而找到字。 若读未命中，从下级存储读出来写入缓存（会产生问题：缓存满了怎么办？），然后再写到被读入的字单元。 问题一：向缓存写数据，缓存满了怎么办？引入缓存失效方案 Least-Recently-Used(LRU) : 替换掉最近被请求最少的对象。在CPU缓存淘汰和虚拟内存系统中效果很好。浏览器一般使用了LRU作为缓存算法。新的对象会被放在缓存的顶部，当缓存达到容量的极限时，底部对象被去除，方法就是把最新被访问的缓存对象放到缓存池的顶部。 Least-Frequently-Used(LFU)：替换掉访问次数最少的缓存，保留最常用的数据。缺点是早期被使用多次的记录之后再不会用到，在该策略下，也很难被删掉，造成”缓存污染“。 Two Queues(2Q)：把被访问的数据放到LRU的缓存中，如果这个对象再一次被访问，就转移到第二个更大的LRU缓存，即使用多级缓存的方式。两个队列都是LRU算法：容量满，底部对象被删掉。 First In First Out(FIFO)：通过一个先进先出队列跟踪缓存对象，最近访问的放到最后，更早的放在前面，当缓存容量满时，del最前面的缓存对象. 问题二：写入缓存操作，缓存与下级缓存，缓存与同级缓存，数据一致性如何保证？（复杂） 要保持数据更新，需要在合适的时候把写数据，传播下去。 一般有两种回写策略：回写（Write back）和直写（Write through）。 write through（直写）：直写是简单的方式，数据更新当前cache, 并直接写入下级存储中，对其更新。 缺点：每次写都会引起总线流量。 write back（回写）：仅更新当前cache，推迟更新下一级存储的更新，在当前数据所在的块（block）要被替换算法替换时，再将它flush回下级回存储器。新的问题产生了，此时Cache中的数据与Memory中的数据不一致，Cache中的数据就变成了脏数据(dirty)。如果其他部件（DMA， 另一个核）访问这段数据的时候，就需要通过 Cache一致性协议(Cache coherency protocol) 保证取到的是最新的数据。 参考：Cache一致性协议 问题：如何处理写未命中（write-misses）? 我们要知道，当前 cpu 向最近的存储发起一个 write request的请求，是没有response data返回给CPU的， 所以需要决定可能发生write-misses如何处理—这又有两种策略： write-allocate: 写分配，即，从低一层的cache中加载相应的 block 到 current cache, 然后再write更新这个 block. not-write-allocate: 避开 current cache, 直接把这个字写到低一层的cache中。 write through通常配合的是not-write-allocate。 write back 通常搭配 write-allocate。 细节随系统不同而不同，通常私有，无文档记录。 编写高速缓存友好的代码 好的程序员总是应该尝试着去编写高速缓存友好的代码。 1. 让最常见的情况运行的更快。 : 需要把注意力集中在核心函数的循环上。2. 对局部变量的反复引用是好的–时间局部性。 :3. 步长为1的引用模式是好的–空间局部性。 : ExampleBad: 12345678int sumarrycols(int a[M][N]){ int i, j, sum=0; for(j=0; j&lt;N; j++) for(i=0; i&lt;M; i++) sum += a[i][j]; //每次步长为 M return sum;} Good: 12345678int sumarrycols(int a[M][N]){ int i, j, sum=0; for(i=0; i&lt;M; i++) for(j=0; j&lt;N; j++) sum += a[i][j]; //每次步长为 1 return sum;} 思考：局部性原理和2/8定理很相似，聪明的人能把原理扩展应用到生活工作设计中，愚钝如我，面对这些原理，只知道：“对啊，很简单”。 然后就没有下文了。为什么？","link":"/2021/11/23/cache-tech/"},{"title":"深入Cache(2) --- 缓存的使用模式","text":"问：我们如何使用缓存？一个普遍的情况，缓存仅仅是缓存，我们read-miss时，去load数据源，update时，先update 数据源，再update cache. 这只是其中一种使用模式，称为Cache-Aside。那么还有哪些模式呢？ 可不可缓存就当做数据源？我们在CPU缓存那里，遇到了write-back, write-through，在应用层是否可以借鉴其思想？ 模式一： Cache-asideRead 场景(伪代码) 12345v = cache.get(k)if (v == null) { v = sor.get(k) cache.put(k, v)} Write 场景(伪代码) 123v = newVsor.put(k, v)cache.put(k, v) Cache-aside 优势和劣势 需要解决缓存穿透问题：同一个key,Cache,SoR都是NULL,每次给的都是空。 需要解决缓存击穿问题：同一个key,Cache没有，SoR有，热点key在失效情况下，被大量get同时访问到SoR。 需要解决缓存雪崩问题: 大量key到期，请求全到SoR，可能引起SoR down机。 模式二： Cache-as-SoR （system-of-record） 把缓存当做最终数据源，读，写处理都交给了cache, 应用层代码完全免责。这种情况cache本身应当支持哪些行为或者配置呢？ 读方案：Read-through（直读）Read 场景(伪代码) 1234567891011//cacheLoader 配置CacheBuilder.newBuilder() .softValues() .maximumSize(5000).expireAfterWrite(2, TimeUnit.MINUTES) .build(new CacheLoader&lt;Integer,Result&lt;Category&gt;&gt;() { // 缓存没有值时，会委托给CacheLoader, 从SoR里读取,写入缓存，返回value @Override public Result&lt;Category&gt; load(final Integer sortId) throwsException { return categoryService.get(sortId); } }); 12//业务代码v = cache.get(k) 写方案一：Write-through（直写）更新SoR优先。 通过一个writer component，like ehcache.CacheWriter，需要业务代码配置如何写入SoR.写SoR就委拖给了Cache。数据一致性得到保证。过程：cache.put(key) -&gt; CacheLoaderWriter写SoR -&gt; SoR成功后，再写入Cache. 写方案二：write-behind（直写）更新缓存优先，cache内部使用线程池异步写，延迟写SoR，业务线程可以先返回。缺点在于，如果缓存失效，数据可能永久丢失。 Cache-as-SoR 优势和劣势Advantages 集中的代码配置read-write的方式 可以方便解决缓存穿透等等问题，因为在CacheLoader里集中load时，可以写同步代码限制一个请求去拿。 每个cache可独立选择write的方式 Disadvantage 怎么使用cache在逻辑里不直观 问：如何选择何种模式？根据使用场景，提问思考再选择： 系统是写多读少的吗？(例如基于时间的日志) 数据是否是只写入一次并被读取多次?(例如用户配置文件) 返回的数据总是惟一的吗?(例如搜索查询) 使用缓存后，命中率如何？ 参考： https://www.ehcache.org/documentation/3.9/caching-patterns.html","link":"/2021/11/30/cache-usage-patterns/"},{"title":"深入Cache(4) --- 分布式缓存","text":"不同于本地缓存，分布式缓存将cache和服务独立开，使得多个服务之间可以共享，共同使用cache。 分布式缓存： Redis vs Memcached 因为公司主要用的redis，所以没做Memcached的整理，相比之下，Memcached真得只是cache，没有persistence的支持，也不支持replication，数据类型单一,只能存可被Serializable/unSerializable的数据, 操作简单。所以重心放在redis上, 简单做个比较。 feat Memcached Redis opensource Yes Yes (multi)get,set Yes Yes incr/decr Yes Yes delete/expiration Yes Yes Range Query - Yes DataType - Yes persistence - Yes replication - Yes Redis对persistence和replication的支持，使得它可做为一个NoSql数据库，这里, 我们仅仅把它当做一个cache. 分布式缓存需要面临的问题数据量的伸缩原因：多服务共同使用一个redis集群，缓存的数据量会随着时间的增加，业务的增加而增加，单个redis的节点不能长期支持，这时就需要多个node一起管理。那么数据又如何比较均衡的分布在这些节点上呢？这是服务端常面临的问题，解决的方式是分布式世界通用的: sharding(分片)。 常用的sharding算法有以下几种： 范围映射：根据key的size范围，比如0~100，环境提供2个节点，node1分配 0 ~ 50， node2 51 ~ 100，方法简单，但不好扩充，要求范围大小是固定的。不好扩展。 hash映射: hash(key)%numberofnode，得到一个数字，为node节点编号，那么该key就由该node负责。 缺点：node改变，Re-balancing代价太大，所有数据都可能要移动 一致性hash：以后写分布式时再介绍。 redis使用Sharding后还有一个缺点: 涉及多个key的操作不能被支持，因为这些Key可能会映射到不同的node. 所以只能操作单key. 访问量的伸缩假如我们的key只放在一个node，其它node没有备份，单机能承载的QPS是有限的，想要承担更高的QPS, 则可以通过读写分离来实现。对于cache来说，需要有多个replications. 这样我们可以通过master负责写，slave可以承担读的请求处理，承担高QPS. 单点故障(failover)解决前一个访问量的问题用到的replications + leader选举，当一个节点宕机，从节点能继续服务，也相应的能解决单点故障的问题，实现HA。稍后介绍。 Redis Cluster 【optional：与分布式相关，与cache无关】分布式要考虑几个环环相扣的问题。记住，我们这里只把redis当cache, 不当db用。但是要同步log，所以redis建议使用了复制功能，请打开master,slave的磁盘持久化配置。 1.数据量大，且需要提高并行度，需要分片，如何sharding? 答：选取分片算法。–&gt; 2.选定分片算法后，要想高可用HA，就需要每个sharding有备份（复制），怎么做?–&gt; 3.采用master-slave方式复制 –&gt; 4.master节点或者slave节点down点后如何处理？（拆分为：故障恢复，容错，leader选举等细分问题） –&gt; 5.master-slave一致性要求要多高？过高的一致性影响低性能，可能用户不接受。（一致性的问题） 问题一: Sharding首先是分布式中的分（sharding）方案，Redis 集群分片算法，没有使用一致性hash, 而是hash映射，Redis集群固定有16384个哈希槽（slot），分给集群中固的节点。客户端内置一个路由规则，根据redis master节点数，和key的hash值，选取相应的分区。 问题二：Redis选取的复制方案 复制的工作原理，是要先选取leader，以节点为leader还是在分片层面，为各分片选leader？ 选取leader后，要决定是采用【sync】，【async】还是【半同步】复制方式？ 初始化leader(master)和slave在配置cluster时，会根据配置提供的node数量和replicas的值提供方案给管理人员，配置完成后，初始的master和slave就自动决定了。 查看集群信息 12345678$ redis-cli -p 7000 cluster nodes3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385503418521 0 connecteda211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385503419023 0 connected97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-114223c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385503419023 3 connected 11423-163833e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385503417005 0 connected 5960-109212938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385503418016 3 connected 复制方式Redis是有多个master,分个每区都有自己的leader。 Redis为了在部分或者大部份节点无法通信下仍然可用，选择了master-slave的复制模型，且每个啥希槽（slot）都有1个master, 和n多个replicas.(1&lt;=n&lt;N, N为机器总数)。并且Redis不同供**强一致性保证**，完整的过程是：1.client更新数据到master -&gt; 2.master记录操作log后直接回复client -&gt; 3.然后master再将操作log同步给slave节点。从上面我们看出：1.从slave读取数据，可能是旧数据;2.master down机后，可能会丢失log，操作失效。 结论：redis采用的是分片后多主复制，异步复制的方式， 非强一致性。 图中，一个多个redis实例，可以部署中一个node上，使用不同的端口。节省资源。 问题三：Leader选举，master节点down掉，Redis如何选举并同步的？这就是共识算法。比如，当所有slave节点，在面临leader挂掉时,如何快速的搭成一致，选取一个新的Leader.Redis采用的是gossip协议，流言成真。也就是nodes相互之间都是广播事件或集群的消息给其它所有的节点。最终消息就被所有人知道了。Redis Cluster要求至少有3个master。 就上图我们举例,假如redis-master-B挂了。任意节点ping不通B后，标识B为PFAIL并把该消息广播所有node，一会儿，当所有node交换信息，发现大部份node都给B标识了PFAIL后，那么更新B的状态为FAIL，再广播出去，直到所有的node都标记为FAIL。那么B的slave结点可以开始选举了。选举过程类似于raft算法，但又有redis自己的特点，如下： 投票顺利，选举成功的过程 投票失败，再次选举 问题四：当slave的同步数据出错或者新的master产生，master与slave之直数据不一样，Redis容错是怎么做的？Redis的处理：数据只从Master节点流向Slave节点。也就是说，如果新选举的master的log少于slave的log,以master为主，当然就会有log丢失的风险。同步有[全量复制]和[增量复制].增量复制的场景： 正常工作时，master向slave同步新的log. master和slave断开后，slave重新连上master,重新获取失连过程中的log. 全量同步的场景 无法进行部分同步时，全量同步。 election 之后的被提升为leader的slave仍然会记录旧master，旧的replicationID和offset(记录偏移位置)，待旧的master返回时，可以在一段时间内继续接受这些丢失的Log。新的master使用新的replicationID。 参考：https://redis.io/topics/replication Redis 集群的配置 我们不一定非要用上面介绍的redis cluster（也可以就单机redis，比如本地开发）, 根据自己服务要使用的缓存大小，数据的重要性和使用的场景可以选择以下几种方式： 主从复制模式 MASTER-SLAVE 即一个master, 多个slave， 不分片。 不能处理上面说的故障转换和容错，因为无法进行leader选举。 也就不是分布式缓存了。 Sentinel(哨兵)模式 即在主从复制模式上，增加了哨兵，由哨兵来帮助处理故障转移，leader选举。 属于高可用的 (HA) MASTER-SLAVE，同样，仍然不分片。 分布式的Redis Cluster总结 只是使用redis进行测试，不需要HA，单机redis满足需求。 需要比较稳定的HA的，数据量完成达到海量，可以不扩展的，Sentinel。 数据海量的超过了单机RAM，redis cluster。","link":"/2021/12/03/catch-redis/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/10/27/hello-world/"}],"tags":[{"name":"科技","slug":"科技","link":"/tags/%E7%A7%91%E6%8A%80/"},{"name":"总结","slug":"总结","link":"/tags/%E6%80%BB%E7%BB%93/"},{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"Ehcache","slug":"Ehcache","link":"/tags/Ehcache/"},{"name":"Guava","slug":"Guava","link":"/tags/Guava/"},{"name":"计算机原理","slug":"计算机原理","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"},{"name":"redis","slug":"redis","link":"/tags/redis/"}],"categories":[{"name":"编程","slug":"programming","link":"/categories/programming/"},{"name":"其它","slug":"其它","link":"/categories/%E5%85%B6%E5%AE%83/"}]}