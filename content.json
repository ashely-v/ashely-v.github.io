{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"5G_and_cloud_conference","text":"工作是我们探索认识世界的的窗口，所以，热爱它。 — 一默 5G是什么? 移动通迅技术 能承载的应用场景(新增) 峰值速率 产业 1G 通话 2K bps 移动电话 2G 短信，文字邮件 10K bps 电话，BB机 3G 网络，音乐 3.8M bps 游戏，互联网 4G 1080影片 0.1-1G bps 电子支付，金融 5G 4K影片，VR直播，物理网 1-10G bps 传统行业,万物互联 5G主要特点： 高速度：承载更多的信息量，1G高清视频数据只需要几秒。 低延时：5G在接入网边缘部署计算，处理和存储功能的云计算设备，使核心网控制功能下沉，减少端到端的传输，减少延时。 大容量：手表等无这里指承载终端数量大，5G采用高频率，但高频率的信号波长短，需要使用更多的微基站，微基站能部署在城市的任何位置，反而能连接更多的设备终端，万物互联成为可能。4G 每平方公里只能支持10个设备，容纳设备有限。 缺点嘛，都源于：高频率波，穿透性差 邓小平说：“科技是第一生产力”。每一次技术革命都带了新了经济增长，5G技术会影响未来20年的经济。所以这是兵家必争之地。 视频会议软件5G的普及，疫情的影响，会对视频会议软件产生如何的影响？ 我已经在新闻里多次看到视频会议，教育，甚至视频手术的影子。大胆想象，万物相连，任何一个设备，有屏，就可以时实沟通，共享场景，解决“当下”紧急问题。如此看来，属于未来系列中的基础需求，很有价值。 阶段 技术标准 应用 主要功能 专用网数字电视会议 H.200系列 国际电视会议，需要通过卫星，光纤等专用网格，费用高 无 基于IP网络视频会议 H.264 WebEx,GIPS 电话会议，文档共享，即实聊天 云视频会议 WebRTC ？ 屏幕共享,录音，录制，全终端支持 什么是WebRTCWebRTC 全称 Web Real-Time Communication。，Google开源GIPS后，与其它机构制定了行业标准，组成了WebRTC。 它并不是单一的协议， 包含了音视频采集，编解码，加密、传输，音视频展示等在内的多个协议标准以及一套基于 JavaScript 的 API，开源，免专利费。通过简单易用的 JavaScript API ，在不安装任何插件的情况下，让浏览器拥有了 P2P音视频和数据分享的能力。 WebRTC 的核心组件 音视频引擎：OPUS、VP8 / VP9、H264 传输层协议：底层传输协议为 UDP, 也可TCP 媒体协议：SRTP / SRTCP 数据协议：DTLS / SCTP P2P 内网穿透：STUN / TURN / ICE / Trickle ICE 信令与 SDP 协商：HTTP / WebSocket / SIP、 Offer Answer 模型 总结作为新人，想要了解云视频开发，从WebRTC入手是必经之路。 附思 即然有屏都可共享“当下”，那么有屏且有网的的地方就能由超级管理员实时监控啊。","link":"/2021/10/29/5G-and-cloud-conference/"},{"title":"第一篇：接受当下","text":"2021-10-18 个人快照迟迟不知如何开始写第一篇博文，但在“追求完美就是最大的障碍”的暗示下，写下本篇， 这是一个总结。 朋友圈总是看到很多人幸福的瞬间，对比当下我的状态，很是糟糕，所有我屏蔽了朋友圈。周四，周五濒临失控，打开联系人却不知道找谁，最终找到了常常去寺里做佛事的朋友。我将烦恼通通诉说给了他。他向我推荐了一个up主,安大熊。于是我的书单里多了两项紧急阅读书《重新认识你自己》，《自卑与超越》。我失控了，我的状态生病了，先爱惜自己，放下欲望，我需要慢下来，好好休息，好好运动。先把身体维持在一个较好的水平。 工作最近工作很无心，戒断公司咖啡导致的偏头疼。工作内容不饱和，需要自己安排工作内容。目前晋升无望。目前的下一个计划是打算将并发并行好好梳理并分享。再下一个计算是梳理Cache并分享。 生活九月一本书没看，十月略看了两本书， 《游戏力养育》，《股市真规则》，然则，读书而不实践，等于白读。计划每月做一次资产负债表。 情绪《为何家会伤人》，家最会伤人。我爱我母亲同时也恨她，无时无刻她都在念叨着家人的不好，指责这里做不好，哪里做不好，明明每个人都有自己的分工，都在做份内之事， 如果她不愿意做,我提议可以分给别人出来，可她不，她会说别人做得不好，横加指责，然后接着自己继续做。搞得我很不喜欢这样的“家”。对家人发火，对外人格外亲切。慢慢的我是不是也习得了这样的不良行为。我害怕。","link":"/2021/10/18/accept-yourself/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/10/27/hello-world/"},{"title":"深入Cache --- CPU和主存之间","text":"本次知识梳理，用3W法。 what, why, how? what：界定问题，搞清楚问题到底是什么； why：分析问题，结构化分析问题的本质原因是什么； how：解决问题，应用目标导向思维解决问题； What：问题是什么？访问太慢！举例：页面次次加载静态资源，慢; 后端服务器直接从数据库获取数据，慢; CPU直接从主存取数据，慢。 Why: 为什么要使用缓存？技术人员为了提高系统的性能，包括响应时间，延迟时间，吞吐量，并发用户数和资源利用率等，用这些指标提高用户体验且节省成本。所以需要把已经取得过的数据，存储在较近较快的地方，便于访问。所以在计算机中缓存随处可见，页面缓存，浏览器缓存，数据库缓存，CPU里的L1,L2,L3级缓存。 How: cache如何解决这个问题？ 以CPU缓存展开详说。局域性原理一个重要的基本事实：程序常常重复使用它们最近用过的数据和指令。 一个程序90%的执行时间花费在仅10%的代码中。 时间局域性是指最近访问过的内容很可能会短期内被再次访问。 空间局域性是指地址相互临近的项目很可能会在短时间内都被用到。 CPU和主存间的速度问题 程序员想拥有足够大的“快速”存储，快速存储非常昂贵，根据局域性原理：大多数程序都不会均衡的访问所有的代码和数据。由此，“在给定的实现技术和功率预算下，硬件越小，速度越快”，就产生了存储的层次结构。这些层次由不同速度，不同大小的存储器组成。 CPU &lt;—&gt; Cache: 是以word(字,大小随CPU架构) 传输的，速度fast. Cache &lt;–&gt; 主存: 是以块传输的(cache block)，一块大小为B=2^b。 L1缓分成两种，一种是指令缓存，一种是数据缓存。L2缓存和L3缓存不分指令和数据。 L1和L2缓存在每一个CPU核中，L3则是所有CPU核心共享的内存。L1、L2、L3的越离CPU近就越小，速度也越快，越离CPU远，速度也越慢。 CPU高速缓存的结构 一个缓存划分为S个组，一个组有E个缓存行（cache line）,一行只有一个B字节的缓存块block。 每个cache一个有效位(valid bit)指明该cache line是否包含有意义的信息。 高速缓存的大小C= B * E * S 检索数据，Read操作 —- 缓存命中的过程 CPU读取字的过程分为：组选择-&gt;行匹配-&gt;字抽取。 组选择， 地址中的S标记，定位到组 行匹配， 地址中的tag标记与组的所有行匹配行t标记位，如果有匹配的行，就命中，否则不命中。 字抽取， 若读命中，再由地址中的b位计算出在块中的偏移位置，从而找到字。 若读未命中，从下级存储读出来写入缓存（会产生问题：缓存满了怎么办？），然后再写到被读入的字单元。 问题一：向缓存写数据，缓存满了怎么办？引入缓存失效方案 Least-Recently-Used(LRU) : 替换掉最近被请求最少的对象。在CPU缓存淘汰和虚拟内存系统中效果很好。浏览器一般使用了LRU作为缓存算法。新的对象会被放在缓存的顶部，当缓存达到容量的极限时，底部对象被去除，方法就是把最新被访问的缓存对象放到缓存池的顶部。 Least-Frequently-Used(LFU)：替换掉访问次数最少的缓存，保留最常用的数据。缺点是早期被使用多次的记录之后再不会用到，在该策略下，也很难被删掉，造成”缓存污染“。 Two Queues(2Q)：把被访问的数据放到LRU的缓存中，如果这个对象再一次被访问，就转移到第二个更大的LRU缓存，即使用多级缓存的方式。两个队列都是LRU算法：容量满，底部对象被删掉。 First In First Out(FIFO)：通过一个先进先出队列跟踪缓存对象，最近访问的放到最后，更早的放在前面，当缓存容量满时，del最前面的缓存对象. 问题二：写入缓存操作，缓存与下级缓存，缓存与同级缓存，数据一致性如何保证？（复杂） 要保持数据更新，需要在合适的时候把写数据，传播下去。 一般有两种回写策略：回写（Write back）和直写（Write through）。 write through（直写）：直写是简单的方式，数据更新当前cache, 并直接写入下级存储中，对其更新。 缺点：每次写都会引起总线流量。 write back（回写）：仅更新当前cache，推迟更新下一级存储的更新，在当前数据所在的块（block）要被替换算法替换时，再将它flush回下级回存储器。新的问题产生了，此时Cache中的数据与Memory中的数据不一致，Cache中的数据就变成了脏数据(dirty)。如果其他部件（DMA， 另一个核）访问这段数据的时候，就需要通过 Cache一致性协议(Cache coherency protocol) 保证取到的是最新的数据。 问题：如何处理写未命中（write-misses）? 我们要知道，当前 cpu 向最近的存储发起一个 write request的请求，是没有data返回给CPU的， 所以需要在发生write-misses进行决定—是否将数据加载到current cache中，这又有两种策略： write-allocate: 写分配，即，从低一层的cache中加载相应的 block 到 current cache, 然后再write更新这个 block. not-write-allocate: 避开 current cache, 直接把这个字写到低一层的cache中。 write through通常配合的是not-write-allocate。 write back 通常搭配 write-allocate。 细节随系统不同而不同，通常私有，无文档记录。 参考：Cache一致性协议 编写高速缓存友好的代码 好的程序员总是应该尝试着去编写高速缓存友好的代码。 1. 让最常见的情况运行的更快。 : 需要把注意力集中在核心函数的循环上。2. 对局部变量的反复引用是好的–时间局部性。 :3. 步长为1的引用模式是好的–空间局部性。 : Bad12345678int sumarrycols(int a[M][N]){ int i, j, sum=0; for(j=0; j&lt;N; j++) for(i=0; i&lt;M; i++) sum += a[i][j]; //每次步长为 M return sum;} Good12345678int sumarrycols(int a[M][N]){ int i, j, sum=0; for(i=0; i&lt;M; i++) for(j=0; j&lt;N; j++) sum += a[i][j]; //每次步长为 1 return sum;} 思考：局部性原理和2/8定理很相似，聪明的人能把原理扩展应用到生活工作设计中，愚钝如我，面对这些原理，只知道：“对啊，很简单”。 然后就没有下文了。为什么？","link":"/2021/11/23/cache-tech/"}],"tags":[{"name":"科技","slug":"科技","link":"/tags/%E7%A7%91%E6%8A%80/"},{"name":"总结","slug":"总结","link":"/tags/%E6%80%BB%E7%BB%93/"},{"name":"计算机原理","slug":"计算机原理","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"},{"name":"cache","slug":"cache","link":"/tags/cache/"}],"categories":[{"name":"编程","slug":"programming","link":"/categories/programming/"},{"name":"其它","slug":"其它","link":"/categories/%E5%85%B6%E5%AE%83/"}]}